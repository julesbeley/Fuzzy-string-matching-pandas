{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "romantic-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import ratio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "productive-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "\n",
    "import string\n",
    "import random\n",
    "\n",
    "text = 'In approximate string matching, the objective is to find matches for short strings \\\n",
    "in many longer texts, in situations where a small number of differences is to be expected. \\\n",
    "The short strings could come from a dictionary, for instance. Here, one of the strings is\\\n",
    "typically short, while the other is arbitrarily long. This has a wide range of applications,\\\n",
    "for instance, spell checkers, correction systems for optical character recognition, and \\\n",
    "software to assist natural language translation based on translation memory.The Levenshtein\\\n",
    "distance can also be computed between two longer strings, but the cost to compute it, which\\\n",
    "is roughly proportional to the product of the two string lengths, makes this impractical. \\\n",
    "Thus, when used to aid in fuzzy string searching in applications such as record linkage, \\\n",
    "the compared strings are usually short to help improve speed of comparisons.[citation needed]\\\n",
    "In linguistics, the Levenshtein distance is used as a metric to quantify the linguistic distance,\\\n",
    "or how different two languages are from one another.[3] It is related to mutual intelligibility,\\\n",
    "the higher the linguistic distance, the lower the mutual intelligibility, and the lower the \\\n",
    "linguistic distance, the higher the mutual intelligibility.'\n",
    "\n",
    "translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "text = set(text.translate(translator).split())\n",
    "\n",
    "unique_strings = []\n",
    "\n",
    "for i in range(100):\n",
    "    length = random.randint(1,3)\n",
    "    unique_strings.append(' '.join(random.sample(text,length)))\n",
    "\n",
    "all_letters = list('abcdefghijklmnopqrstuvwxyz')\n",
    "new_strings = []\n",
    "\n",
    "for string in random.choices(unique_strings,k=300):\n",
    "    n_changes = random.randint(0,3)\n",
    "    new_string = list(string)\n",
    "    if len(new_string) > 1:\n",
    "        for change in range(n_changes):\n",
    "            to_change_index = random.randint(1,len(new_string)-1)\n",
    "            replace_by = random.sample(all_letters,1)[0]\n",
    "            new_string[to_change_index] = replace_by\n",
    "    new_strings.append(''.join(new_string))\n",
    "    \n",
    "all_strings = unique_strings + new_strings\n",
    "random.shuffle(all_strings)\n",
    "        \n",
    "test_df = pd.DataFrame(all_strings,columns=['strings'])\n",
    "test_df['key'] = test_df.index\n",
    "\n",
    "test_df = test_df[['key','strings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "traditional-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from Levenshtein import ratio\n",
    "import numpy as np\n",
    "\n",
    "dictionary = dict(zip(test_df.key,test_df.strings))\n",
    "unique_keys = [list(dictionary.keys())[0]]\n",
    "unique_keys\n",
    "\n",
    "duplicates = []\n",
    "threshold = 0.7\n",
    "\n",
    "for key in dictionary:\n",
    "    results = [ratio(dictionary[key],dictionary[unique_key]) for unique_key in unique_keys]\n",
    "    if all(result < threshold for result in results):\n",
    "        unique_keys.append(key)    \n",
    "    else:\n",
    "        indices = []\n",
    "        for index,result in enumerate(results):\n",
    "            if result >= threshold:\n",
    "                indices.append(index)\n",
    "        original = [unique_keys[index] for index in indices]\n",
    "        true_original = original[0]\n",
    "        if len(original) > 1:\n",
    "            for other_original in original[1:]:\n",
    "                unique_keys.remove(other_original)\n",
    "                duplicates.append([true_original,other_original])\n",
    "                for rank,duplicate in enumerate(duplicates):\n",
    "                    if duplicate[0] == other_original:\n",
    "                        duplicates[rank][0] = true_original\n",
    "        if true_original != key:\n",
    "            duplicates.append([true_original,key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
